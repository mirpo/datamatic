version: 1.0

steps:
  - name: generate_subtopics
    model: ollama:llama3.2
    prompt: |
      I am building a dataset of Git-related questions and commands. List exactly 30 distinct subtopics that comprehensively cover core and advanced Git usage. Do not number the subtopics. Separate them only with commas, with no additional text or formatting.
      Each subtopic should be a short phrase, and they should be relevant to Git commands, concepts, or workflows. The subtopics should be diverse and cover various aspects of Git, including but not limited to version control, branching, merging, rebasing, conflict resolution, and collaboration.
    maxResults: 1
    jsonSchema:
      type: object
      properties:
        subtopics:
          type: array
          minItems: 30
          maxItems: 30
          items:
            type: string
      required:
        - subtopics

  - name: split_into_unique_subtopics
    type: cli
    cmd: |
      cat ./generate_subtopics.jsonl | jq -c '.response.subtopics[]' | sort | uniq | jq -c '{id: . | @base64, topic: .}' > ./split_into_unique_subtopics.jsonl
    outputFilename: split_into_unique_subtopics.jsonl

  - name: generate_instructions
    model: ollama:llama3.2
    prompt: |
      Generate list of 100 concise user instructions about the following Git topic: {{.split_into_unique_subtopics.topic}}.
      These instructions list will be used to train an AI assistant.

      - 70% of the instructions should reflect beginner-level understanding, using casual or non-technical phrasing.
      - 30% should reflect intermediate to advanced users, including Git jargon where appropriate.
      - Keep each instruction brief and focused.
      - Do not number the items. Separate each instruction with a newline. Return only the list.
    modelConfig:
      temperature: 0.9
      maxTokens: 5000
    maxResults: split_into_unique_subtopics.$length # for each unique subtopic generate N instructions
    jsonSchema:
      type: object
      properties:
        instructions:
          type: array
          items:
            type: string
      required:
        - instructions

  - name: split_into_unique_instructions
    type: cli
    cmd: |
      cat ./generate_instructions.jsonl | jq -c '.response.instructions[]' | sort | uniq | jq -c '{id: . | @base64, instruction: .}' > ./split_into_unique_instructions.jsonl
    outputFilename: split_into_unique_instructions.jsonl

  - name: generate_answer
    model: ollama:llama3.2
    prompt: |
      Given the user instruction related to Git below, generate a clear, accurate, and concise response.

      - Include actual Git commands where appropriate.
      - Provide examples for complex tasks.
      - Keep the tone friendly, but not overly verbose.
      - Avoid unnecessary tangents or deep Git internals unless the instruction explicitly requires it.

      Instruction: "{{.split_into_unique_instructions.instruction}}"
    maxResults: split_into_unique_instructions.$length

  - name: instruction_response
    type: cli
    cmd: |
      cat ./generate_answer.jsonl | jq -c '{instruction: .values.".split_into_unique_instructions.instruction".value, response: .response}' > ./instruction_response.jsonl
    outputFilename: instruction_response.jsonl

  - name: rate
    model: ollama:llama3.2
    systemPrompt: |
      You are an expert evaluator specializing in Git documentation and instruction assessment. Your task is to analyze instruction-response pairs related to Git usage and provide numerical scores across five key dimensions. Each evaluation should be thorough, consistent, and based on clear criteria.
      Evaluation Criteria

      Helpfulness (0-10):

      How well does the response address the user's needs?
      Does it provide practical, actionable information?
      Are there useful examples or explanations?
      Does it anticipate potential issues or edge cases?


      Correctness (0-10):

      Is the technical information accurate?
      Are Git commands and concepts explained correctly?
      Are there any errors or misleading information?
      Does it follow Git best practices?


      Coherence (0-10):

      Is the response well-structured and logical?
      Does it flow naturally from one point to the next?
      Are concepts introduced in a sensible order?
      Is the language clear and consistent?


      Complexity (0-10):

      How advanced is the Git knowledge required?
      Does it match the complexity level of the question?
      Is technical jargon used appropriately?
      Is the difficulty level appropriate for the target audience?


      Verbosity (0-10):

      Is the length appropriate for the content?
      Is the explanation concise yet complete?
      Are there unnecessary repetitions or tangents?
      Is the information density appropriate?
    prompt: |
      Please evaluate the following Git instruction-response pair and provide scores for helpfulness, correctness, coherence, complexity, and verbosity on a scale of 0-10:

      INSTRUCTION:
      {{.instruction_response.instruction}}

      RESPONSE:
      {{.instruction_response.response}}

      Please provide your evaluation in the JSON format specified below, with a brief justification for each score.
    modelConfig:
      temperature: 0.9
      maxTokens: 5000
    maxResults: instruction_response.$length # for each instruction-response pair generate an evaluation
    jsonSchema:
      type: object
      properties:
        helpfulness:
          type: integer
          minimum: 0
          maximum: 10
        correctness:
          type: integer
          minimum: 0
          maximum: 10
        coherence:
          type: integer
          minimum: 0
          maximum: 10
        complexity:
          type: integer
          minimum: 0
          maximum: 10
        verbosity:
          type: integer
          minimum: 0
          maximum: 10
      required:
        - helpfulness
        - correctness
        - coherence
        - complexity
        - verbosity

  - name: result
    type: cli
    cmd: |
      cat ./rate.jsonl | jq -c '{instruction: .values.".instruction_response.response".value, response: .values.".instruction_response.response".value, evaluation: .response}' > result.jsonl
    outputFilename: result.jsonl
